{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "import torch\n",
    "import gc\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# path to the directory that CONTAINS the package folder\n",
    "project_root = Path(\"/home/benedetti/PL\")   # adjust to your real path\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PL.model.model import TwoBodiesModel\n",
    "from PL.dataset.random_features import RandomDatasetPowerLaw, GeneralDataset\n",
    "from PL.utils.saving import init_training_h5, save_training, load_training\n",
    "from PL.utils.functions import start_overlap, compute_asymmetry, overlap, basins_of_attraction_inp_vectors\n",
    "\n",
    "from PL.training.training_RF import train_model, initialize\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "data_PATH = \"./data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0520, 0.0280,\n",
      "        0.0520, 0.0340, 0.0420, 0.0200, 0.0480, 0.0240, 0.0600, 0.0500, 0.0300,\n",
      "        0.0160, 0.0440, 0.0380, 0.0440, 0.0380, 0.0200, 0.0340, 0.0540, 0.0420,\n",
      "        0.0260, 0.0640, 0.0240, 0.0240, 0.0240, 0.0260, 0.0480, 0.0260, 0.0900,\n",
      "        0.0500, 0.0180, 0.0300, 0.0220, 0.0740, 0.0440, 0.0380, 0.1280, 0.0780,\n",
      "        0.0360, 0.0880, 0.0080, 0.0500, 0.0380, 0.0060, 0.0840, 0.0120, 0.0860,\n",
      "        0.0500, 0.0140, 0.0300, 0.0320, 0.0600, 0.0920, 0.0720, 0.0300, 0.0460,\n",
      "        0.0180, 0.0580, 0.0140, 0.0400, 0.0180, 0.0140, 0.0220, 0.0280, 0.0160,\n",
      "        0.0360, 0.0420, 0.0160, 0.0080, 0.0480, 0.0420, 0.0220, 0.0460, 0.0360,\n",
      "        0.0300, 0.0600, 0.0960, 0.0200, 0.0520, 0.0080, 0.1140, 0.0300, 0.0260,\n",
      "        0.0140, 0.0840, 0.0740, 0.0300, 0.0180, 0.0420, 0.0560, 0.0540, 0.0600,\n",
      "        0.0200], device='cuda:1')\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Nature of variables and loss\n",
    "d=1\n",
    "spin_type = \"vector\"\n",
    "\n",
    "pick_biased = True\n",
    "\n",
    "# Step\n",
    "n = 100\n",
    "\n",
    "L=3\n",
    "eta=2.\n",
    "alpha_P = 10.\n",
    "alpha_D = 0.1\n",
    "\n",
    "N = 1000\n",
    "P = int(alpha_P*N)\n",
    "D = int(alpha_D*N)\n",
    "d = 1\n",
    "seed = 100\n",
    "\n",
    "\n",
    "dataset = RandomDatasetPowerLaw(P, N, D, d, eta=eta, L=L, seed=seed, spin_type=spin_type, coefficients=\"binary\", shift=0, pick_biased=pick_biased)\n",
    "model  = TwoBodiesModel(N, d, spin_type=spin_type, device=device)\n",
    "xi = dataset.xi.to(device)\n",
    "f =  dataset.f.to(device)\n",
    "model.Hebb(xi, \"Tensorial\")\n",
    "x = f.clone()\n",
    "for i_n in range(n):\n",
    "    x = model.dyn_step(x)\n",
    "overlap_k = torch.abs(torch.einsum(\"kia,kia->k\", f, x))/N\n",
    "\n",
    "print(overlap_k[:100])\n",
    "\n",
    "def count_overlaps_above_threshold(overlaps, thr):\n",
    "    count = 0\n",
    "    for overlap in overlaps:\n",
    "        if overlap > thr:\n",
    "            count += 1\n",
    "        else:\n",
    "            break  # Stop at the first overlap that is lower than the threshold\n",
    "    return count\n",
    "\n",
    "num_stable_f = count_overlaps_above_threshold(overlap_k, 0.99)\n",
    "\n",
    "print(num_stable_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable: tensor([0.5520, 0.5200, 0.4820, 0.4840, 0.5040, 0.5140, 0.0460, 0.5080, 0.5060,\n",
      "        0.5200, 0.5180, 0.5100, 0.5040, 0.4760, 0.5040, 0.4720, 0.4880, 0.4780,\n",
      "        0.4780, 0.5100], device='cuda:1')\n",
      "F Stable: tensor([[0.0140, 1.0000, 1.0000,  ..., 0.0140, 1.0000, 0.0100],\n",
      "        [0.0320, 0.0100, 0.0100,  ..., 0.0320, 0.0100, 1.0000],\n",
      "        [1.0000, 0.0140, 0.0140,  ..., 1.0000, 0.0140, 0.0320],\n",
      "        ...,\n",
      "        [0.0340, 0.0160, 0.0160,  ..., 0.0340, 0.0160, 0.0540],\n",
      "        [0.0060, 0.0600, 0.0600,  ..., 0.0060, 0.0600, 0.0180],\n",
      "        [0.0140, 0.0200, 0.0200,  ..., 0.0140, 0.0200, 0.0220]],\n",
      "       device='cuda:1')\n",
      "Unstable: tensor([0.0040, 0.0200, 0.0520, 0.0480, 0.0380, 0.0120, 0.0180, 0.0440, 0.0120,\n",
      "        0.0280, 0.0180, 0.0200, 0.0440, 0.0840, 0.1040, 0.0340, 0.0080, 0.0300,\n",
      "        0.0620, 0.0520], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "P_hat = 20\n",
    "\n",
    "stable_features = torch.arange(0, num_stable_f)\n",
    "unstable_features = torch.arange(num_stable_f, D)\n",
    "\n",
    "stable_xi = dataset.get_generalization_selected_features(P_hat, stable_features, L=L)\n",
    "unstable_xi = dataset.get_generalization_selected_features(P_hat, unstable_features, L=L)\n",
    "\n",
    "stable_xi = stable_xi.to(device)\n",
    "unstable_xi = unstable_xi.to(device)\n",
    "\n",
    "x = stable_xi.clone()\n",
    "\n",
    "for i_n in range(n):\n",
    "    x = model.dyn_step(x)\n",
    "\n",
    "overlap_stable = torch.abs(torch.einsum(\"kia,kia->k\", stable_xi, x))/N\n",
    "overlap_stable_f = torch.abs(torch.einsum(\"kia,gia->kg\", dataset.f.to(device), x))/N\n",
    "\n",
    "print(\"Stable:\", overlap_stable)\n",
    "print(\"F Stable:\", overlap_stable_f)\n",
    "\n",
    "x = unstable_xi.clone()\n",
    "\n",
    "for i_n in range(n):\n",
    "    x = model.dyn_step(x)\n",
    "\n",
    "overlap_unstable = torch.abs(torch.einsum(\"kia,kia->k\", unstable_xi, x))/N\n",
    "\n",
    "print(\"Unstable:\", overlap_unstable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and training\n",
    "l=1.\n",
    "lr = 0.1*N\n",
    "\n",
    "epochs=10000\n",
    "valid_every = 2\n",
    "max_grad = 20.\n",
    "init_overlap = 1.\n",
    "n=100\n",
    "\n",
    "loss_type = \"CE\"\n",
    "l2 = False\n",
    "alpha=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:10000  lr:100.0  max_norm:20.0  init_overlap:1.0  n:100  l:1.0\n"
     ]
    }
   ],
   "source": [
    "model_PL  = TwoBodiesModel(N, d, spin_type=spin_type, device=device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model_PL.parameters(), lr=lr)\n",
    "\n",
    "xi = dataset.xi.to(device)\n",
    "f =  dataset.f.to(device)\n",
    "#model_PL.Hebb(xi, \"Tensorial\")\n",
    "\n",
    "P_hat = 100\n",
    "\n",
    "dataset_f = GeneralDataset(D, dataset.f)\n",
    "xi_generalization = dataset.get_generalization(P_hat, L=L)\n",
    "dataset_generalization = GeneralDataset(P_hat, xi_generalization)\n",
    "batch_size = P\n",
    "batch_size_f = D\n",
    "\n",
    "model2 = TwoBodiesModel(N, d, spin_type=spin_type, device=device)\n",
    "model2.to(device)\n",
    "model2.Hebb(dataset.xi.to(device), 'Tensorial')  # Applying the Hebb rule\n",
    "J2 = model2.J.squeeze().cpu().detach().numpy()\n",
    "norm_J2 = np.linalg.norm(J2)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=2)\n",
    "dataloader_f = torch.utils.data.DataLoader(dataset_f, batch_size=batch_size_f, shuffle=False, drop_last=False, num_workers=2)\n",
    "dataloader_generalization = torch.utils.data.DataLoader(dataset_generalization, batch_size=P_hat, shuffle=False, drop_last=False, num_workers=2)\n",
    "\n",
    "epochs_to_save = [10,50,200]\n",
    "save = True\n",
    "print(\"epochs:{}  lr:{}  max_norm:{}  init_overlap:{}  n:{}  l:{}\".format(epochs, lr, max_grad, init_overlap, n, l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PL_vector_CE_GD_PW_eta2.0_N_4000_P_40000_D400_l_1.0_epochs10000_lr100.0_l2False.pth\n"
     ]
    }
   ],
   "source": [
    "model_name_base = \"PL_{}_{}_GD_PW_eta{}_N_{}_P_{}_D{}_l_{}_epochs{}_lr{}_l2{}\".format(spin_type, loss_type, eta, N, P, D, l, epochs, lr, l2)\n",
    "model_name = model_name_base + \".pth\"\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# epoch lambda train_loss learning_rate train_metric features_metric generalization_metric // // // norm_x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.5753056406974792 0.015420211479067802 100.0 0.9735081 0.21120441 0.9614801 0.9911869 0.46301582 0.98037004 12649.1103515625\n",
      "200 0.6233677268028259 0.009490774013102055 100.0 0.98328125 0.24035066 0.9662651 0.99598116 0.5628047 0.98706007 12649.1103515625\n",
      "300 0.6683117151260376 0.007116770837455988 100.0 0.9873645 0.27089942 0.96627015 0.99768007 0.6149022 0.9900951 12649.1103515625\n",
      "400 0.7081565856933594 0.0057362401857972145 100.0 0.9898301 0.29536688 0.9711601 0.9985752 0.64749724 0.99218017 12649.1103515625\n",
      "500 0.743388831615448 0.004809495992958546 100.0 0.9917001 0.3155619 0.97118014 0.9991062 0.6697722 0.99329513 12649.1103515625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_PL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_generalization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_overlap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_J2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs_to_save\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_type\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PL/PL/training/training_RF.py:75\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, dataloader_f, dataloader_gen, epochs, learning_rate, max_grad, device, data_PATH, init_overlap, n, l, optimizer, J2, norm_J2, valid_every, epochs_to_save, model_name_base, save, l2, alpha, loss_type)\u001b[0m\n\u001b[1;32m     72\u001b[0m train_loss_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Training batch-wise\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_element \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     76\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     77\u001b[0m     inp_data \u001b[38;5;241m=\u001b[39m batch_element\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/rbms-py310/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/rbms-py310/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1448\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1448\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rbms-py310/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1412\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1414\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/rbms-py310/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1243\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1243\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rbms-py310/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/envs/rbms-py310/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rbms-py310/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/rbms-py310/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/rbms-py310/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model_PL, dataloader, dataloader_f, dataloader_generalization, epochs, \n",
    "    lr, max_grad, device, data_PATH, init_overlap, \n",
    "    n, l, optimizer, J2, norm_J2, valid_every, epochs_to_save, model_name_base, save, l2, alpha,loss_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.0240, 0.9980, 0.9980, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9940, 1.0000, 0.0000, 1.0000,\n",
      "        0.0520, 0.0780, 0.0000, 0.0400, 1.0000, 0.0140, 0.9960, 1.0000, 0.0760,\n",
      "        0.9980, 0.0040, 1.0000, 0.0340, 1.0000, 0.0420, 0.9860, 0.0220, 0.0360,\n",
      "        0.0780, 0.0680, 0.0960, 1.0000, 0.9980, 0.0300, 0.9960, 0.0060, 0.0400,\n",
      "        0.0360, 0.0840, 0.0740, 0.9860, 0.0120, 0.0600, 0.0620, 0.0400, 0.0280,\n",
      "        0.0840], device='cuda:1')\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "x = f.clone()\n",
    "for i_n in range(n):\n",
    "    x = model_PL.dyn_step(x)\n",
    "overlap_k = torch.abs(torch.einsum(\"kia,kia->k\", f, x))/N\n",
    "\n",
    "print(overlap_k[:100])\n",
    "\n",
    "def count_overlaps_above_threshold(overlaps, thr):\n",
    "    count = 0\n",
    "    for overlap in overlaps:\n",
    "        if overlap > thr:\n",
    "            count += 1\n",
    "        else:\n",
    "            break  # Stop at the first overlap that is lower than the threshold\n",
    "    return count\n",
    "\n",
    "num_stable_f = count_overlaps_above_threshold(overlap_k, 0.99)\n",
    "\n",
    "print(num_stable_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:1')\n",
      "F Stable: tensor([0.0300, 0.0520, 0.0160, 0.4600, 0.0460, 0.4740, 0.5580, 0.0140, 0.0380,\n",
      "        0.0120, 0.0140, 0.0000, 0.0100, 0.0280, 0.0020, 0.0160, 0.0020, 0.0200,\n",
      "        0.0260, 0.0500, 0.0380, 0.0520, 0.0300, 0.0260, 0.0380, 0.0600, 0.0240,\n",
      "        0.0200, 0.0380, 0.0620, 0.0080, 0.0300, 0.0280, 0.0100, 0.0440, 0.0420,\n",
      "        0.0520, 0.0360, 0.0240, 0.0680, 0.0020, 0.0220, 0.0120, 0.0240, 0.0040,\n",
      "        0.0120, 0.0540, 0.0180, 0.0220, 0.0520, 0.0200, 0.0100, 0.0380, 0.0040,\n",
      "        0.0220, 0.0720, 0.0040, 0.0740, 0.0360, 0.0320, 0.0020, 0.0320, 0.0160,\n",
      "        0.0500, 0.0080, 0.0740, 0.0080, 0.0160, 0.0840, 0.0720, 0.0300, 0.0420,\n",
      "        0.0620, 0.0180, 0.0100, 0.0060, 0.0020, 0.0200, 0.0520, 0.0440, 0.0140,\n",
      "        0.0480, 0.0360, 0.0940, 0.0120, 0.0160, 0.0020, 0.0300, 0.0080, 0.0680,\n",
      "        0.0160, 0.0140, 0.0040, 0.0740, 0.0120, 0.0000, 0.0020, 0.0260, 0.0100,\n",
      "        0.0220], device='cuda:1')\n",
      "Unstable: tensor([0.0300, 0.0560, 0.5000, 0.5320, 0.4880, 0.4780, 0.5260, 0.5040, 0.5280,\n",
      "        0.0300, 0.4940, 0.0540, 0.0340, 0.4880, 0.4360, 0.4480, 0.5000, 0.0300,\n",
      "        0.4780, 0.5240], device='cuda:1')\n",
      "F Unstable: tensor([0.0320, 0.0100, 0.0260, 0.0180, 1.0000, 0.0240, 0.0160, 0.0280, 0.0200,\n",
      "        0.0100, 0.0360, 0.0300, 0.0080, 0.0260, 0.0480, 0.0180, 0.0040, 0.0060,\n",
      "        0.0280, 0.0400, 0.0280, 0.0180, 0.0040, 0.0240, 0.0080, 0.0180, 0.0140,\n",
      "        0.0100, 0.0040, 0.0280, 0.0100, 0.0560, 0.0260, 0.0560, 0.0060, 0.0280,\n",
      "        0.0060, 0.0020, 0.0060, 0.0060, 0.0680, 0.0200, 0.0100, 0.0380, 0.0380,\n",
      "        0.0180, 0.0480, 0.0520, 0.0800, 0.0140, 0.0220, 0.0360, 0.0200, 0.0340,\n",
      "        0.0640, 0.0580, 0.0140, 0.0280, 0.0180, 0.0140, 0.0440, 0.0700, 0.0340,\n",
      "        0.0280, 0.0500, 0.0120, 0.0140, 0.0620, 0.0300, 0.0260, 0.0320, 0.0200,\n",
      "        0.0160, 0.0280, 0.0680, 0.0840, 0.0960, 0.0020, 0.0060, 0.0300, 0.0280,\n",
      "        0.0260, 0.0180, 0.0280, 0.0060, 0.0340, 0.0120, 0.0320, 0.0340, 0.0100,\n",
      "        0.0220, 0.0280, 0.0020, 0.0080, 0.0060, 0.0020, 0.0280, 0.0200, 0.0560,\n",
      "        0.0280], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "P_hat = 20\n",
    "\n",
    "num_stable_f = 10\n",
    "\n",
    "stable_features = torch.arange(0, num_stable_f)\n",
    "unstable_features = torch.arange(num_stable_f, D)\n",
    "\n",
    "stable_xi = dataset.get_generalization_selected_features(P_hat, stable_features, L=L)\n",
    "unstable_xi = dataset.get_generalization_selected_features(P_hat, unstable_features, L=L)\n",
    "\n",
    "stable_xi = stable_xi.to(device)\n",
    "unstable_xi = unstable_xi.to(device)\n",
    "\n",
    "x = stable_xi.clone()\n",
    "\n",
    "for i_n in range(n):\n",
    "    x = model_PL.dyn_step(x)\n",
    "\n",
    "overlap_stable = torch.abs(torch.einsum(\"kia,kia->k\", stable_xi, x))/N\n",
    "overlap_stable_f = torch.abs(torch.einsum(\"kia,gia->kg\", dataset.f.to(device), x))/N\n",
    "\n",
    "print(\"Stable:\", overlap_stable)\n",
    "print(\"F Stable:\", overlap_stable_f[:,0])\n",
    "\n",
    "x = unstable_xi.clone()\n",
    "\n",
    "for i_n in range(n):\n",
    "    x = model_PL.dyn_step(x)\n",
    "\n",
    "overlap_unstable = torch.abs(torch.einsum(\"kia,kia->k\", unstable_xi, x))/N\n",
    "overlap_unstable_f = torch.abs(torch.einsum(\"kia,gia->kg\", dataset.f.to(device), x))/N\n",
    "\n",
    "print(\"Unstable:\", overlap_unstable)\n",
    "print(\"F Unstable:\", overlap_unstable_f[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable: tensor([1.0000, 1.0000, 0.4980,  ..., 1.0000, 1.0000, 1.0000], device='cuda:1')\n",
      "F Stable: tensor([1.0000, 0.0100, 0.0140, 0.0060, 0.0320, 0.0280, 0.0320, 0.0520, 0.0280,\n",
      "        0.0140, 0.0040, 0.0420, 0.0200, 0.0220, 0.0240, 0.0180, 0.0080, 0.0300,\n",
      "        0.0160, 0.0440, 0.0160, 0.0060, 0.0080, 0.0200, 0.0080, 0.0540, 0.0420,\n",
      "        0.0260, 0.0640, 0.0240, 0.0020, 0.0240, 0.0260, 0.0480, 0.0260, 0.0160,\n",
      "        0.0500, 0.0180, 0.0300, 0.0220, 0.0080, 0.0440, 0.0380, 0.0260, 0.0020,\n",
      "        0.0020, 0.0880, 0.0080, 0.0240, 0.0380, 0.0060, 0.0200, 0.0120, 0.0860,\n",
      "        0.0040, 0.0140, 0.0300, 0.0320, 0.0020, 0.0460, 0.0720, 0.0300, 0.0220,\n",
      "        0.0040, 0.0580, 0.0000, 0.0140, 0.0180, 0.0140, 0.0220, 0.0280, 0.0160,\n",
      "        0.0360, 0.0120, 0.0160, 0.0080, 0.0160, 0.0420, 0.0220, 0.0180, 0.0360,\n",
      "        0.0300, 0.0300, 0.0960, 0.0020, 0.0020, 0.0080, 0.0160, 0.0300, 0.0260,\n",
      "        0.0140, 0.0840, 0.0740, 0.0040, 0.0180, 0.0420, 0.0560, 0.0160, 0.0600,\n",
      "        0.0200], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "P_hat = 20\n",
    "\n",
    "xi_gen = dataset.get_generalization(P_hat, L=L)\n",
    "\n",
    "xi_gen = xi_gen.to(device)\n",
    "\n",
    "x = xi_gen.clone()\n",
    "\n",
    "for i_n in range(n):\n",
    "    x = model_PL.dyn_step(x)\n",
    "\n",
    "overlap_stable = torch.abs(torch.einsum(\"kia,kia->k\", xi_gen, x))/N\n",
    "overlap_stable_f = torch.abs(torch.einsum(\"kia,gia->kg\", dataset.f.to(device), x))/N\n",
    "\n",
    "print(\"Stable:\", overlap_stable)\n",
    "print(\"F Stable:\", overlap_stable_f[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step\n",
    "n = 100\n",
    "d=1\n",
    "L=3\n",
    "eta=0.75\n",
    "alpha_D = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and training\n",
    "l=1.\n",
    "\n",
    "epochs=100\n",
    "valid_every = 100\n",
    "max_grad = 20.\n",
    "init_overlap = 1.\n",
    "n=100\n",
    "\n",
    "#training\n",
    "loss_type = \"CE\"\n",
    "l2 = False\n",
    "alpha=1.\n",
    "spin_type = \"vector\"\n",
    "pick_biased = True\n",
    "epochs_to_save = [10000]\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAP_compute_overlap_array_model(model, dataset, N, P_hat):\n",
    "\n",
    "    xi = dataset.xi.to(device)\n",
    "\n",
    "    x = xi.clone()\n",
    "\n",
    "    for i_n in range(n):\n",
    "        x = model.dyn_step(x)\n",
    "\n",
    "    overlap_train = torch.abs(torch.einsum(\"kia,kia->k\", xi, x))/N\n",
    "\n",
    "    xi_gen = dataset.get_generalization(P_hat).to(device)\n",
    "\n",
    "    x = xi_gen.clone()\n",
    "\n",
    "    for i_n in range(n):\n",
    "        x = model.dyn_step(x)\n",
    "\n",
    "    overlap_test = torch.abs(torch.einsum(\"kia,kia->k\", xi_gen, x))/N\n",
    "\n",
    "    return [overlap_train.cpu().numpy(), overlap_test.cpu().numpy()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_model(N, P, D):\n",
    "    lr = 0.05*N\n",
    "\n",
    "    optimizer = torch.optim.SGD(model_PL.parameters(), lr=lr)\n",
    "    \n",
    "    P_hat = 10\n",
    "    \n",
    "    dataset_f = GeneralDataset(D, dataset.f)\n",
    "    xi_generalization = dataset.get_generalization(P_hat, L=L)\n",
    "    dataset_generalization = GeneralDataset(P_hat, xi_generalization)\n",
    "    batch_size = P\n",
    "    batch_size_f = D\n",
    "    \n",
    "    model2 = TwoBodiesModel(N, d, spin_type=spin_type, device=device)\n",
    "    model2.to(device)\n",
    "    model2.Hebb(dataset.xi.to(device), 'Tensorial')  # Applying the Hebb rule\n",
    "    J2 = model2.J.squeeze().cpu().detach().numpy()\n",
    "    norm_J2 = np.linalg.norm(J2)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=2)\n",
    "    dataloader_f = torch.utils.data.DataLoader(dataset_f, batch_size=batch_size_f, shuffle=False, drop_last=False, num_workers=2)\n",
    "    dataloader_generalization = torch.utils.data.DataLoader(dataset_generalization, batch_size=P_hat, shuffle=False, drop_last=False, num_workers=2)\n",
    "\n",
    "    train_model(\n",
    "        model_PL, dataloader, dataloader_f, dataloader_generalization, epochs, \n",
    "        lr, max_grad, device, data_PATH, init_overlap, \n",
    "        n, l, optimizer, J2, norm_J2, valid_every, epochs_to_save, model_name_base, save, l2, alpha,loss_type, verbose=False\n",
    "    )\n",
    "\n",
    "    cuda_cleanup(dataset_f, dataset_generalization,\n",
    "     dataloader, dataloader_f, dataloader_generalization,\n",
    "     optimizer)\n",
    "    \n",
    "def cuda_cleanup(*objs):\n",
    "    for o in objs:\n",
    "        try:\n",
    "            del o\n",
    "        except Exception:\n",
    "            pass\n",
    "    gc.collect()\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias varying $\\alpha_P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [19:13, 230.65s/it]\n"
     ]
    }
   ],
   "source": [
    "P_hat = 1000\n",
    "\n",
    "N = 2000\n",
    "\n",
    "#alpha_P_arr = np.array([0.01,0.0316,0.1,0.316,1.,3.16,10.,31.6])\n",
    "\n",
    "alpha_P_arr = np.array([0.01778, 0.05623, 0.1778, 0.5623, 1.778, 5.623, 17.78\n",
    "])\n",
    "\n",
    "seeds_arr = np.arange(1000, 1005)\n",
    "\n",
    "to_save = np.empty((len(alpha_P_arr), len(seeds_arr)), dtype=object)\n",
    "\n",
    "\n",
    "for i_s, seed in tqdm(enumerate(seeds_arr)):\n",
    "    for i_a, alpha_P in enumerate(alpha_P_arr):\n",
    "        P = int(alpha_P*N)\n",
    "        D = int(alpha_D*N)\n",
    "        \n",
    "        dataset = RandomDatasetPowerLaw(P, N, D, d, eta=eta, L=L, seed=seed, spin_type=spin_type, coefficients=\"binary\", shift=0, pick_biased=pick_biased)\n",
    "        model_PL  = TwoBodiesModel(N, d, spin_type=spin_type, device=device)\n",
    "\n",
    "        model_name_base = \".\"\n",
    "        \n",
    "        train_single_model(N, P, D)\n",
    "        \n",
    "        to_save[i_a, i_s] = GAP_compute_overlap_array_model(model_PL, dataset, N, P_hat) \n",
    "\n",
    "        cuda_cleanup(model_PL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_train = np.empty(len(alpha_P_arr), dtype=object)\n",
    "std_train = np.empty(len(alpha_P_arr), dtype=object)\n",
    "means_test = np.empty(len(alpha_P_arr), dtype=object)\n",
    "std_test = np.empty(len(alpha_P_arr), dtype=object)\n",
    "\n",
    "for i_a, alpha_P in enumerate(alpha_P_arr):\n",
    "    D = int(alpha_D*N)\n",
    "    P = int(alpha_P*N)\n",
    "    arr_train = np.zeros((len(seeds_arr), P))\n",
    "    for i_s in range(len(seeds_arr)):\n",
    "        arr_train[i_s] = to_save[i_a, i_s][0]\n",
    "    means_train[i_a] = arr_train.mean(axis=0)\n",
    "    std_train[i_a] = arr_train.std(axis=0)\n",
    "    arr_test = np.zeros((len(seeds_arr), P_hat))\n",
    "    for i_s in range(len(seeds_arr)):\n",
    "        arr_test[i_s] = to_save[i_a, i_s][1]\n",
    "    means_test[i_a] = arr_test.mean(axis=0)\n",
    "    std_test[i_a] = arr_test.std(axis=0)\n",
    "\n",
    "fname = \"GAP_PL_curves_eta{}_N{}_alpha_D{}_L{}_epochs{}_varying_alpha_P_mid\".format(eta, N, alpha_D,L,epochs)\n",
    "\n",
    "final_dict = {\n",
    "    \"means_train\": means_train,\n",
    "    \"std_train\": std_train,\n",
    "    \"means_test\": means_test,\n",
    "    \"std_test\": std_test,\n",
    "    \"N\": N,\n",
    "    \"alpha_D\": alpha_D,\n",
    "    \"alpha_P_arr\": alpha_P_arr,\n",
    "    \"seeds_arr\": seeds_arr,\n",
    "    \"eta\": eta\n",
    "}\n",
    "\n",
    "np.savez(\"/home/benedetti/RF_power_law/data/\"+fname, **final_dict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fname = \"GAP_PL_curves_eta{}_N{}_alpha_D{}_L{}_epochs{}_varying_alpha_P.npz\".format(eta, N, alpha_D, L,epochs)\n",
    "saved_dict = np.load(\"/home/benedetti/RF_power_law/data/\"+fname, allow_pickle=True)\n",
    "\n",
    "mean_arr_train = saved_dict[\"means_train\"]\n",
    "std_arr_train = saved_dict[\"std_train\"]\n",
    "mean_arr_test = saved_dict[\"means_test\"]\n",
    "std_arr_test = saved_dict[\"std_test\"]\n",
    "alpha_P_array = saved_dict[\"alpha_P_arr\"]\n",
    "aD =  saved_dict[\"alpha_D\"]\n",
    "N =  saved_dict[\"N\"]\n",
    "eta_value = saved_dict[\"eta\"]\n",
    "s_arr = saved_dict[\"seeds_arr\"]\n",
    "\n",
    "fname = \"GAP_PL_curves_eta{}_N{}_alpha_D{}_L{}_epochs{}_varying_alpha_P_mid.npz\".format(eta, N, alpha_D, L,epochs)\n",
    "saved_dict_mid = np.load(\"/home/benedetti/RF_power_law/data/\"+fname, allow_pickle=True)\n",
    "\n",
    "mean_arr_train_mid = saved_dict_mid[\"means_train\"]\n",
    "std_arr_train_mid = saved_dict_mid[\"std_train\"]\n",
    "mean_arr_test_mid = saved_dict_mid[\"means_test\"]\n",
    "std_arr_test_mid = saved_dict_mid[\"std_test\"]\n",
    "alpha_P_array_mid = saved_dict_mid[\"alpha_P_arr\"]\n",
    "aD_mid =  saved_dict_mid[\"alpha_D\"]\n",
    "N_mid =  saved_dict_mid[\"N\"]\n",
    "eta_value_mid = saved_dict_mid[\"eta\"]\n",
    "s_arr_mid = saved_dict_mid[\"seeds_arr\"]\n",
    "\n",
    "alpha_tot = np.sort(np.concatenate((alpha_P_array, alpha_P_array_mid), axis=0))\n",
    "\n",
    "\n",
    "train = np.zeros(len(alpha_P_array)+len(alpha_P_array_mid))\n",
    "std_train = np.zeros(len(alpha_P_array)+len(alpha_P_array_mid))\n",
    "test = np.zeros(len(alpha_P_array)+len(alpha_P_array_mid))\n",
    "std_test = np.zeros(len(alpha_P_array)+len(alpha_P_array_mid))\n",
    "\n",
    "for i_a, alpha_P in enumerate(alpha_P_array):\n",
    "    i = 2*i_a\n",
    "    train[i] = mean_arr_train[i_a].mean()\n",
    "    std_train[i] = std_arr_train[i_a].mean()/math.sqrt(float(len(std_arr_train[i_a])))\n",
    "    test[i] = mean_arr_test[i_a].mean()\n",
    "    std_test[i] = std_arr_test[i_a].mean()/math.sqrt(float(len(std_arr_test[i_a])))\n",
    "    i = i+1\n",
    "    if i_a < len(alpha_P_array)-1:\n",
    "        train[i] = mean_arr_train_mid[i_a].mean()\n",
    "        std_train[i] = std_arr_train_mid[i_a].mean()/math.sqrt(float(len(std_arr_train[i_a])))\n",
    "        test[i] = mean_arr_test_mid[i_a].mean()\n",
    "        std_test[i] = std_arr_test_mid[i_a].mean()/math.sqrt(float(len(std_arr_test[i_a])))\n",
    "\n",
    "plt.errorbar(alpha_tot, train, std_train/math.sqrt(float(len(s_arr))), label=\"Train\")\n",
    "plt.errorbar(alpha_tot, test, std_test/math.sqrt(float(len(s_arr))), label=\"Test\")\n",
    "\n",
    "plt.xlabel(r\"Load $\\alpha_P$\")\n",
    "plt.ylabel(\"Overlap\")\n",
    "plt.title(rf\"$\\eta={eta}$, $L={L}$, $N={N}$, $\\alpha_D={alpha_D}$\")\n",
    "plt.ylim((-0.01,1.05))\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rbms-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
